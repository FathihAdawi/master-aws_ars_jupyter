{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DeviceID: 75\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from configure import db_init\n",
    "from decimal import Decimal\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# [SETTING DISPLAY OPTION DATAFRAME]\n",
    "pd.set_option(\"display.max_rows\", 100, \"display.max_columns\", 100)\n",
    "\n",
    "# [VARIABLES DB]\n",
    "filename = 'db_dwh.ini'\n",
    "section = 'tpadw_db'\n",
    "db_info = db_init(filename, section)\n",
    "\n",
    "# [CONNECTION & CURSOR]\n",
    "db_connection = psycopg2.connect(**db_info)\n",
    "db_cursor = db_connection.cursor()\n",
    "\n",
    "\"\"\"\n",
    "    GET ALL TK KEMANDORAN PANEN, LOADING, PERAWATAN, SUPERVISI\n",
    "\"\"\"\n",
    "query1 = 'select \"ESTATE\", \"DEVICE ID\", \"DEVICE NAME\", \"DEVICE CODE\" from \"L1_Fact_AWS_ARS\";'\n",
    "db_cursor.execute(query1)\n",
    "df_m_aws_ars = pd.DataFrame(\n",
    "    db_cursor.fetchall(),\n",
    "    columns=[\"ESTATE\", \"DEVICE ID\", \"DEVICE NAME\", \"DEVICE CODE\"]\n",
    ")\n",
    "\n",
    "list_Device_ID = list(df_m_aws_ars[\"DEVICE ID\"])\n",
    "print(\"Total DeviceID: \"+str(len(list_Device_ID)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def API_retrieved_aws_ars():\n",
    "    print(\"=== Custom Retrieved Date IOT AWS ARS ====\")\n",
    "    v_month = input(\"Month: \")\n",
    "    v_day = input(\"Day: \")\n",
    "    v_year = input(\"Year: \")\n",
    "\n",
    "    # # query_delete_raw = 'delete from \"L1_AWS_ARS_RAW\" where date_part(\\'month\\', \"FullDate_WIB\"::date) = ' \\\n",
    "    # #                     +v_month+' and date_part(\\'year\\', \"FullDate_WIB\"::date) = '+v_year+' ;'\n",
    "    # query_delete_raw = 'delete from \"L1_AWS_ARS_RAW\";'\n",
    "    # print(query_delete_raw)\n",
    "    # db_cursor.execute(query_delete_raw)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            custom_EOD = (datetime.strptime(str(v_year + '-' + v_month + '-' + v_day), \"%Y-%m-%d\") +\n",
    "                          pd.offsets.MonthEnd(0)).date()\n",
    "            custom_SOD = datetime.strptime(str(v_year + '-' + v_month + '-' + v_day), \"%Y-%m-%d\").date()\n",
    "            print(\"Start Of Date: \" + str(custom_SOD) + \"\\n\" + \"End Of Date: \" + str(custom_EOD))\n",
    "            \n",
    "            for d in list_Device_ID:\n",
    "                print(d)\n",
    "\n",
    "                r = requests.get(\n",
    "                    \"http://forwarding.mertani.my.id/pull-sensor-record?deviceId=\" + d + \"&fromDate=\" + str(\n",
    "                        str(custom_SOD)) + \"&endDate\"\n",
    "                                      \"=\" + str(custom_EOD) + \"&zone=0\",\n",
    "                    headers={\"Token\": \"IOTYDI002456Y202100D110008I44380334T999999P999999P9999999A\"}\n",
    "                )\n",
    "\n",
    "                data = json.loads(r.text)\n",
    "                if \"data\" in data:\n",
    "                    if bool(data[\"data\"]):\n",
    "                        print(d)\n",
    "                        df_aws_ars = pd.DataFrame(data[\"data\"])\n",
    "                        df_aws_ars.reset_index(\n",
    "                            drop=True,\n",
    "                            inplace=True\n",
    "                        )\n",
    "\n",
    "                        df_aws_ars['unixTime'] = df_aws_ars['unixTime'].astype(int)\n",
    "\n",
    "                        \"\"\"\n",
    "                            Convert unixTime to WIB UTC+07:00 as FullDate_WIB\n",
    "                        \"\"\"\n",
    "                        df_aws_ars['FullDate_WIB'] = pd.to_datetime(\n",
    "                            df_aws_ars['unixTime'],\n",
    "                            unit='s'\n",
    "                        ).dt.tz_localize('UTC').dt.tz_convert('Asia/Jakarta')\n",
    "                        df_aws_ars['FullDate_WIB'] = df_aws_ars[\n",
    "                            'FullDate_WIB'\n",
    "                        ].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                        \"\"\"\n",
    "                            Convert unixTime to WITA UTC+08:00 as FullDate_WITA\n",
    "                        \"\"\"\n",
    "                        df_aws_ars['FullDate_WITA'] = pd.to_datetime(\n",
    "                            df_aws_ars['unixTime'],\n",
    "                            unit='s'\n",
    "                        ).dt.tz_localize('UTC').dt.tz_convert('Asia/Kuala_Lumpur')\n",
    "                        df_aws_ars['FullDate_WITA'] = df_aws_ars[\n",
    "                            'FullDate_WITA'\n",
    "                        ].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                        \"\"\"\n",
    "                            Insert ModifyDatetime where is data created\n",
    "                        \"\"\"\n",
    "                        df_aws_ars['ModifyDateTime'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                        df_aws_ars.rename(columns=lambda x: x.split(' ')[0], inplace=True)\n",
    "                        df_cols_1 = df_aws_ars[['lat_1', 'long_1', 'batt_1']]\n",
    "                        cols = df_aws_ars.columns.values\n",
    "                        new_cols = [re.split(r'_', item)[-1] for item in cols]\n",
    "                        df_aws_ars.columns = new_cols\n",
    "                        df_aws_ars.drop(['1'], axis=1, inplace=True)\n",
    "                        cols_without_1 = df_cols_1.columns.values\n",
    "                        new_cols_1 = [re.split(r'_', item)[0] for item in cols_without_1]\n",
    "                        df_cols_1.columns = new_cols_1\n",
    "\n",
    "                        df_cols_1.rename(\n",
    "                            columns={'lat': 'Latitude', 'long': 'Longitude', 'batt': 'Battery'},\n",
    "                            inplace=True\n",
    "                        )\n",
    "\n",
    "                        df_aws_ars.rename(\n",
    "                            columns={'devId': 'DeviceID', 'name': 'DeviceName', 'sig': 'Signal_Val',\n",
    "                                     'unixTime': 'UnixTime', 'WIB': 'FullDate_WIB', 'WITA': 'FullDate_WITA',\n",
    "                                     'slrRad': 'SolarRad_Val', 'winDir': 'WindDir_Val', 'arHum': 'AirHmd_Val',\n",
    "                                     'winSpe': 'WindSpd_Val', 'arPre': 'AirPrs_Val', 'par': 'PhotoActRad_Val',\n",
    "                                     'batt': 'Battery_Val', 'arTem': 'AirTem_Val', 'rnFal': 'RainFal_Val'},\n",
    "                            inplace=True\n",
    "                        )\n",
    "\n",
    "                        df_cols_1[[\n",
    "                            'Latitude', 'Longitude', 'Battery'\n",
    "                        ]] = df_cols_1[[\n",
    "                            'Latitude', 'Longitude', 'Battery'\n",
    "                        ]].astype(str)\n",
    "\n",
    "                        df_aws_ars[[\n",
    "                            'Signal_Val', 'SolarRad_Val', 'WindDir_Val', 'AirHmd_Val', 'UnixTime',\n",
    "                            'WindSpd_Val', 'AirPrs_Val', 'PhotoActRad_Val', 'Battery_Val', 'AirTem_Val', 'RainFal_Val'\n",
    "                        ]] = df_aws_ars[[\n",
    "                            'Signal_Val', 'SolarRad_Val', 'WindDir_Val', 'AirHmd_Val', 'UnixTime',\n",
    "                            'WindSpd_Val', 'AirPrs_Val', 'PhotoActRad_Val', 'Battery_Val', 'AirTem_Val', 'RainFal_Val',\n",
    "                        ]].applymap(str)\n",
    "\n",
    "                        m_df_aws_ars = pd.concat([df_cols_1, df_aws_ars], axis=1, join='inner')\n",
    "\n",
    "                        m_df_aws_ars[[\n",
    "                            'Longitude', 'Latitude', 'Battery', 'Signal_Val', 'SolarRad_Val', 'WindDir_Val',\n",
    "                            'AirHmd_Val',\n",
    "                            'WindSpd_Val', 'AirPrs_Val', 'PhotoActRad_Val', 'Battery_Val', 'AirTem_Val', 'RainFal_Val'\n",
    "                        ]] = m_df_aws_ars[[\n",
    "                            'Longitude', 'Latitude', 'Battery', 'Signal_Val', 'SolarRad_Val', 'WindDir_Val',\n",
    "                            'AirHmd_Val',\n",
    "                            'WindSpd_Val', 'AirPrs_Val', 'PhotoActRad_Val', 'Battery_Val', 'AirTem_Val', 'RainFal_Val'\n",
    "                        ]].replace({'nan': 0})\n",
    "\n",
    "                        m_df_aws_ars = m_df_aws_ars.replace({np.nan: None})\n",
    "\n",
    "                        m_df_aws_ars_2 = m_df_aws_ars[['DeviceID', 'DeviceName', 'FullDate_WIB', 'FullDate_WITA',\n",
    "                                                       'UnixTime', 'Longitude', 'Latitude', 'Battery', 'Signal_Val',\n",
    "                                                       'SolarRad_Val', 'WindDir_Val', 'AirHmd_Val', 'WindSpd_Val',\n",
    "                                                       'AirPrs_Val', 'PhotoActRad_Val', 'Battery_Val', 'AirTem_Val',\n",
    "                                                       'RainFal_Val', 'ModifyDateTime']]\n",
    "\n",
    "                        tuple_aws_ars = tuple(map(tuple, m_df_aws_ars_2.values))\n",
    "                        \n",
    "                        query_insert_raw = \"insert into \\\"L1_AWS_ARS_RAW\\\" (\\\"DeviceID\\\", \\\"DeviceName\\\", \" \\\n",
    "                                           \"\\\"FullDate_WIB\\\", \\\"FullDate_WITA\\\", \\\"UnixTime\\\", \\\"Longitude\\\", \" \\\n",
    "                                           \"\\\"Latitude\\\", \\\"Battery\\\", \\\"Signal_Val\\\", \\\"SolarRad_Val\\\", \" \\\n",
    "                                           \"\\\"WindDir_Val\\\", \\\"AirHmd_Val\\\", \\\"WindSpd_Val\\\", \\\"AirPrs_Val\\\", \" \\\n",
    "                                           \"\\\"PhotoActRad_Val\\\", \\\"Battery_Val\\\", \\\"AirTem_Val\\\", \" \\\n",
    "                                           \"\\\"RainFal_Val\\\", \\\"ModifyDateTime\\\") \" \\\n",
    "                                           \"VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,\" \\\n",
    "                                           \"%s,%s,%s)\"\n",
    "                        \n",
    "                        db_cursor.executemany(\n",
    "                            query_insert_raw,\n",
    "                            tuple_aws_ars\n",
    "                        )\n",
    "                        db_connection.commit()\n",
    "                    else:\n",
    "                        print(\"Data is empty in \" + d)\n",
    "                else:\n",
    "                    print(\"There is no DATA in Device: \" + d)\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Your Format Date Doesn't Match [Year]-[Month]-[day]!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_retrieved_aws_ars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def API_clean_aws_ars():\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleaning Data Frame After Input Data Raw\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    #[Delete filter from L2_AWS_ARS Table]\n",
    "    query_delete = 'delete from \"L2_AWS_ARS\";'\n",
    "    db_cursor.execute(query_delete)\n",
    "\n",
    "    #[Get Data from L1_AWS_ARS_RAW Table]\n",
    "    query_clean = 'select \"DeviceID\", \"DeviceName\", \"FullDate_WIB\", \"FullDate_WITA\", \"UnixTime\", \"Longitude\", ' \\\n",
    "                '\"Latitude\", \"Battery\", \"Signal_Val\", \"SolarRad_Val\", \"WindDir_Val\", \"AirHmd_Val\", ' \\\n",
    "                '\"WindSpd_Val\", \"AirPrs_Val\", \"PhotoActRad_Val\", \"Battery_Val\", \"AirTem_Val\", ' \\\n",
    "                '\"RainFal_Val\", \"ModifyDateTime\" from \"L1_AWS_ARS_RAW\";'\n",
    "    db_cursor.execute(query_clean)\n",
    "    df_clean_data = pd.DataFrame(\n",
    "        db_cursor.fetchall(),\n",
    "        columns=[\"DeviceID\", \"DeviceName\", \"FullDate\", \"FullDate_WITA\", \"UnixTime\", \"Longitude\", \"Latitude\",\n",
    "                 \"Battery\", \"Signal_Val\", \"SolarRad_Val\", \"WindDir_Val\", \"AirHmd_Val\", \"WindSpd_Val\", \n",
    "                 \"AirPrs_Val\", \"PhotoActRad_Val\", \"Battery_Val\", \"AirTem_Val\", \"RainFal_Val\", \"ModifyDateTime\"]\n",
    "    )\n",
    "\n",
    "    for i, y in df_clean_data[['Signal_Val', 'SolarRad_Val', 'WindDir_Val', 'AirHmd_Val', 'WindSpd_Val', 'AirPrs_Val',\n",
    "                               'PhotoActRad_Val', 'Battery_Val', 'AirTem_Val', 'RainFal_Val']].items():\n",
    "        df_clean_data[i] = df_clean_data[i].apply(lambda x: None if 'undefined' in x else x)\n",
    "\n",
    "    for i, y in df_clean_data[['Signal_Val', 'SolarRad_Val', 'WindDir_Val', 'AirHmd_Val', 'WindSpd_Val', 'AirPrs_Val',\n",
    "                               'PhotoActRad_Val', 'Battery_Val', 'AirTem_Val', 'RainFal_Val']].items():\n",
    "        \n",
    "        df_clean_data[i] = df_clean_data[i].str.extract(r'(\\'value\\'.+\\')')\n",
    "        df_clean_data[i] = df_clean_data[i].str.replace(r'[\\'value\\':\\s\\']', '', regex=True)\n",
    "\n",
    "\n",
    "    df_clean_data.rename(\n",
    "        columns={'ModifyDateTime': 'ModifyDate'},\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    df_clean_data.insert(18, \"ModifyStatus\", \"I\")\n",
    "\n",
    "    df_clean_data[['Latitude', 'Longitude', 'Battery', 'Signal_Val', \n",
    "                   'SolarRad_Val', 'WindDir_Val', 'AirHmd_Val',\n",
    "                   'WindSpd_Val', 'AirPrs_Val', 'PhotoActRad_Val', \n",
    "                   'Battery_Val', 'AirTem_Val', 'RainFal_Val'\n",
    "                   ]] = df_clean_data[['Latitude', 'Longitude', 'Battery', 'Signal_Val', 'SolarRad_Val', \n",
    "                                       'WindDir_Val', 'AirHmd_Val', 'WindSpd_Val', 'AirPrs_Val', \n",
    "                                       'PhotoActRad_Val', 'Battery_Val', 'AirTem_Val', 'RainFal_Val'\n",
    "                                       ]].astype(float)\n",
    "\n",
    "    tuple_clean_aws_ars = tuple(map(tuple, df_clean_data.values))\n",
    "\n",
    "    query_insert_clean_raw = \"insert into \\\"L2_AWS_ARS\\\" (\\\"DeviceID\\\", \\\"DeviceName\\\", \\\"FullDate\\\", \" \\\n",
    "                             \"\\\"FullDate_WITA\\\", \" \\\n",
    "                             \"\\\"UnixTime\\\", \\\"Longitude\\\", \\\"Latitude\\\", \\\"Battery\\\", \\\"Signal_Val\\\", \" \\\n",
    "                             \"\\\"SolarRad_Val\\\", \\\"WindDir_Val\\\", \\\"AirHmd_Val\\\", \\\"WindSpd_Val\\\", \\\"AirPrs_Val\\\", \" \\\n",
    "                             \"\\\"PhotoActRad_Val\\\", \\\"Battery_Val\\\", \\\"AirTem_Val\\\", \\\"RainFal_Val\\\", \" \\\n",
    "                             \"\\\"ModifyStatus\\\", \\\"ModifyDate\\\") VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,\" \\\n",
    "                             \"%s,%s,%s,%s,%s)\"\n",
    "\n",
    "    db_cursor.executemany(\n",
    "        query_insert_clean_raw,\n",
    "        tuple_clean_aws_ars\n",
    "    )\n",
    "    db_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_clean_aws_ars()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
